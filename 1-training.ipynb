{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b70d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training_pipeline import train_and_evaluate\n",
    "from src.cohort import cohort_stability\n",
    "from src.simulation import flip_top_positives\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aadf280",
   "metadata": {},
   "source": [
    "### Load Data and Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0fae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t0 = pd.read_csv('data/train-test-data/train_t0_30.csv')\n",
    "test_t0 =  pd.read_csv('data/train-test-data/test_t0_30.csv')\n",
    "\n",
    "train_t1 = pd.read_csv('data/train-test-data/train_t1_30.csv')\n",
    "test_t1 =  pd.read_csv('data/train-test-data/test_t1_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['still_unemployed', 'employed_before', 'receipt_leh_before',\n",
    "                        'receipt_lhg_before', 'se_before',\n",
    "                        'ASU_notue_seeking_before', 'ASU_other_before', 'break_before',\n",
    "                        'lastjob_none', 'lastjob_type', 'lastjob_pt', 'lastjob_niveau',\n",
    "                        'lastjob_leih', 'lastjob_befrist', 'lastjob_industry',\n",
    "                        'female', 'german_citizen',  'education_level_imputed', 'school_completed',\n",
    "                        'occupation_skill_level', ]\n",
    "ordinal_features = ['lastjob_tot_dur_cat', 'age_cat', 'LHG_total_cat', 'LHG_tot_dur_cat', 'LHG_m_dur_cat',\n",
    "                    'LEH_total_cat', 'LEH_tot_dur_cat', 'LEH_m_dur_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "  'commuter', \n",
    "  'tsince_lm_contact_cat', \n",
    "  'tsince_ft_lm_contact_cat', \n",
    "  'tsince_ein_erw1_cat',\n",
    "  'emp1_total_dur_cat',\n",
    "  'emp1_total_dur_cat',\n",
    "  'emp1_total_cat',\n",
    "  'emp1_m_dur_cat',\n",
    "  'bula',\n",
    "  'est_total_cat',\n",
    "  'days_remaining_in_spell'\n",
    "]\n",
    "\n",
    "train_t0 = train_t0.drop(columns=cols_to_drop)\n",
    "test_t0 = test_t0.drop(columns=cols_to_drop)\n",
    "train_t1 = train_t1.drop(columns=cols_to_drop)\n",
    "test_t1 = test_t1.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23164b95",
   "metadata": {},
   "source": [
    "### Analyze Feature and Outcome Stability over Time Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cohort_stability(train_t0, train_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_stability(test_t0, test_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fde8fa",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6715e1",
   "metadata": {},
   "source": [
    "### Train $t = 0$, Test $t = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737af74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, results = train_and_evaluate(\n",
    "    train_df=train_t0,\n",
    "    test_df=test_t1,\n",
    "    outcome_col='remains_ue_horizon_days',\n",
    "    categorical_features=categorical_features,\n",
    "    ordinal_features=ordinal_features,\n",
    "    filter_train_to_unemployed=False,\n",
    "    filter_test_to_unemployed=True,\n",
    "    run_name = 'train-t0-test-t1',\n",
    "    save_dir='results/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690c421",
   "metadata": {},
   "source": [
    "### Train $t = 1$, Test $t = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3635a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, results = train_and_evaluate(\n",
    "    train_df=train_t1,\n",
    "    test_df=test_t1,\n",
    "    outcome_col='remains_ue_horizon_days',\n",
    "    categorical_features=categorical_features,\n",
    "    ordinal_features=ordinal_features,\n",
    "    filter_train_to_unemployed=False,\n",
    "    filter_test_to_unemployed=True,\n",
    "    run_name = 'train-t1-test-t1',\n",
    "    save_dir='results/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de02882",
   "metadata": {},
   "source": [
    "### Train $t = 1$, Test $t = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ded147",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, results = train_and_evaluate(\n",
    "    train_df=train_t1,\n",
    "    test_df=test_t0,\n",
    "    outcome_col='remains_ue_horizon_days',\n",
    "    categorical_features=categorical_features,\n",
    "    ordinal_features=ordinal_features,\n",
    "    filter_train_to_unemployed=False,\n",
    "    filter_test_to_unemployed=True,\n",
    "    run_name = 'train-t1-test-t0',\n",
    "    save_dir='results/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73836cb4",
   "metadata": {},
   "source": [
    "## Simulation of Performative Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, results = train_and_evaluate(\n",
    "    train_df=train_t0,\n",
    "    test_df=test_t1,\n",
    "    outcome_col='remains_ue_horizon_days',\n",
    "    categorical_features=categorical_features,\n",
    "    ordinal_features=ordinal_features,\n",
    "    filter_train_to_unemployed=False,\n",
    "    filter_test_to_unemployed=True,\n",
    "    run_name = 'train-t0-test-t1',\n",
    "    save_dir='results/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = np.linspace(0.01, 0.5, 50)\n",
    "save_dir = \"results/performative-sweep\"\n",
    "\n",
    "base_model, base_results = train_and_evaluate(\n",
    "    train_df=train_t0,\n",
    "    test_df=test_t1,\n",
    "    outcome_col='remains_ue_horizon_days',\n",
    "    categorical_features=categorical_features,\n",
    "    ordinal_features=ordinal_features,\n",
    "    filter_train_to_unemployed=False,\n",
    "    filter_test_to_unemployed=True,\n",
    "    run_name=\"base_model\",\n",
    "    save_dir=save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0997e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictions = base_results['train']['probabilities']\n",
    "y_train_orig = base_results['train']['y_true'].values\n",
    "\n",
    "# Run sweep\n",
    "for i, p in enumerate(p_values):\n",
    "    print(f\"\\n[{i+1}/{len(p_values)}] p = {p:.4f}\")\n",
    "    \n",
    "    # Create modified training data with flipped outcomes\n",
    "    train_t0_modified = train_t0.copy()\n",
    "    y_flipped = flip_top_positives(base_predictions, y_train_orig, p)\n",
    "    train_t0_modified['remains_ue_horizon_days'] = y_flipped\n",
    "    \n",
    "    print(f\"   Flipped {(y_train_orig != y_flipped).sum()} outcomes\")\n",
    "    \n",
    "    model, results = train_and_evaluate(\n",
    "        train_df=train_t0_modified,\n",
    "        test_df=test_t1,\n",
    "        outcome_col='remains_ue_horizon_days',\n",
    "        categorical_features=categorical_features,\n",
    "        ordinal_features=ordinal_features,\n",
    "        filter_train_to_unemployed=False,\n",
    "        filter_test_to_unemployed=False,\n",
    "        run_name=f\"p_{p:.4f}\",\n",
    "        save_dir=save_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed09e4f",
   "metadata": {},
   "source": [
    "## Theorem 3.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14beb0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t0 = pd.read_csv('data/train-test-data/train_t0_3_7.csv')\n",
    "test_t0 =  pd.read_csv('data/train-test-data/test_t0_3_7.csv')\n",
    "\n",
    "train_t1 = pd.read_csv('data/train-test-data/train_t1_3_7.csv')\n",
    "test_t1 =  pd.read_csv('data/train-test-data/test_t1_3_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3897cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "  'commuter', \n",
    "  'tsince_lm_contact_cat', \n",
    "  'tsince_ft_lm_contact_cat', \n",
    "  'tsince_ein_erw1_cat',\n",
    "  'emp1_total_dur_cat',\n",
    "  'emp1_total_dur_cat',\n",
    "  'emp1_total_cat',\n",
    "  'emp1_m_dur_cat',\n",
    "  'bula',\n",
    "  'est_total_cat',\n",
    "  'days_remaining_in_spell',\n",
    "  'still_unemployed',\n",
    "  'ASU_notue_seeking_before',\n",
    "  'ASU_other_before',\n",
    "  'employed_before',\n",
    "  'receipt_leh_before',\n",
    "  'lastjob_industry',\n",
    "  'lastjob_befrist',\n",
    "  'LEH_total_cat'\n",
    "]\n",
    "\n",
    "train_t0 = train_t0.drop(columns=cols_to_drop)\n",
    "test_t0 = test_t0.drop(columns=cols_to_drop)\n",
    "train_t1 = train_t1.drop(columns=cols_to_drop)\n",
    "test_t1 = test_t1.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ce685",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cohort_stability(train_t0, train_t1, outcome_cols=['remains_ue_horizon_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training_pipeline import prepare_features_and_outcome\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sort by person_id\n",
    "train_t0_sorted = train_t0.sort_values('person_id').reset_index(drop=True)\n",
    "train_t1_sorted = train_t1.sort_values('person_id').reset_index(drop=True)\n",
    "\n",
    "# Prepare features\n",
    "X_t0, y_t0, cat_categories, ord_mappings = prepare_features_and_outcome(\n",
    "    train_t0_sorted, outcome_col='remains_ue_horizon_days',\n",
    "    categorical_features=categorical_features,\n",
    "    ordinal_features=ordinal_features,\n",
    "    filter_to_unemployed=False\n",
    ")\n",
    "\n",
    "X_t1, y_t1, _, _ = prepare_features_and_outcome(\n",
    "    train_t1_sorted, outcome_col='remains_ue_horizon_days',\n",
    "    categorical_features=categorical_features,\n",
    "    ordinal_features=ordinal_features,\n",
    "    filter_to_unemployed=False,\n",
    "    cat_categories=cat_categories,\n",
    "    ord_mappings=ord_mappings\n",
    ")\n",
    "\n",
    "# Scale and PCA - use fit() + transform() for both\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "X_t0_scaled = scaler.fit_transform(X_t0)\n",
    "X_t1_scaled = scaler.transform(X_t1)\n",
    "\n",
    "pca.fit(X_t0_scaled)\n",
    "X_t0_pca = pca.transform(X_t0_scaled)\n",
    "X_t1_pca = pca.transform(X_t1_scaled)\n",
    "\n",
    "print(f\"Explained variance: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "# Build DataFrames\n",
    "pca_t0 = pd.DataFrame(X_t0_pca, columns=['PC1', 'PC2', 'PC3', 'PC4'])\n",
    "pca_t0['person_id'] = train_t0_sorted['person_id'].values\n",
    "\n",
    "pca_t1 = pd.DataFrame(X_t1_pca, columns=['PC1', 'PC2', 'PC3', 'PC4'])\n",
    "pca_t1['person_id'] = train_t1_sorted['person_id'].values\n",
    "\n",
    "cohort_stability(pca_t0, pca_t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d943da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale existing PCA to [0, 1]\n",
    "minmax = MinMaxScaler()\n",
    "pca_t0_scaled = minmax.fit_transform(pca_t0[['PC1', 'PC2', 'PC3', 'PC4']])\n",
    "pca_t1_scaled = minmax.transform(pca_t1[['PC1', 'PC2', 'PC3', 'PC4']])\n",
    "\n",
    "# Training data: x from t1, y from t0\n",
    "pca_train = pd.DataFrame(pca_t1_scaled, columns=['PC1', 'PC2', 'PC3', 'PC4'])\n",
    "pca_train['person_id'] = pca_t1['person_id'].values\n",
    "pca_train['remains_ue_horizon_days'] = y_t0.values\n",
    "\n",
    "# Train\n",
    "model, results = train_and_evaluate(\n",
    "    train_df=pca_train,\n",
    "    test_df=pca_train,\n",
    "    outcome_col='remains_ue_horizon_days',\n",
    "    categorical_features=[],\n",
    "    ordinal_features=[],\n",
    "    filter_train_to_unemployed=False,\n",
    "    filter_test_to_unemployed=False,\n",
    "    run_name=\"pca_x2_y1\",\n",
    "    save_dir=\"results/pca-models\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
